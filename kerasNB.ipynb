{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94391e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74f6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aabb468",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # ~5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    # ~5% of older individuals who did not experience side effetcs\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    # ~5% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    # ~5% of older individuals who did experience side effetcs\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb35a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = np.array(train_samples)\n",
    "train_labels= np.array(train_labels)\n",
    "train_samples,train_labels = shuffle(train_samples,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e39448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b85b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29885057]\n",
      " [0.73563218]\n",
      " [0.        ]\n",
      " ...\n",
      " [0.85057471]\n",
      " [0.40229885]\n",
      " [0.91954023]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e877ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f7c5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of GPUs available 0\n"
     ]
    }
   ],
   "source": [
    "physical_device = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(\"Num of GPUs available\" , len(physical_device))\n",
    "#tf.config.experimental.set_memory_growth(physical_device[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045c709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 16, input_shape=(1,), activation = 'relu'),\n",
    "    Dense(units = 32, activation = 'relu'),\n",
    "    Dense(units = 2 , activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ae11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                32        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "097db3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate=0.0001),loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "320601a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b495f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "331fbd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 - 1s - loss: 0.7000 - accuracy: 0.5005 - 827ms/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "210/210 - 0s - loss: 0.6717 - accuracy: 0.6362 - 197ms/epoch - 940us/step\n",
      "Epoch 3/30\n",
      "210/210 - 0s - loss: 0.6346 - accuracy: 0.7419 - 195ms/epoch - 929us/step\n",
      "Epoch 4/30\n",
      "210/210 - 0s - loss: 0.6005 - accuracy: 0.7852 - 221ms/epoch - 1ms/step\n",
      "Epoch 5/30\n",
      "210/210 - 0s - loss: 0.5687 - accuracy: 0.8148 - 229ms/epoch - 1ms/step\n",
      "Epoch 6/30\n",
      "210/210 - 0s - loss: 0.5382 - accuracy: 0.8324 - 294ms/epoch - 1ms/step\n",
      "Epoch 7/30\n",
      "210/210 - 0s - loss: 0.5085 - accuracy: 0.8457 - 217ms/epoch - 1ms/step\n",
      "Epoch 8/30\n",
      "210/210 - 0s - loss: 0.4795 - accuracy: 0.8629 - 203ms/epoch - 965us/step\n",
      "Epoch 9/30\n",
      "210/210 - 0s - loss: 0.4519 - accuracy: 0.8781 - 180ms/epoch - 857us/step\n",
      "Epoch 10/30\n",
      "210/210 - 0s - loss: 0.4268 - accuracy: 0.8862 - 234ms/epoch - 1ms/step\n",
      "Epoch 11/30\n",
      "210/210 - 0s - loss: 0.4040 - accuracy: 0.8905 - 191ms/epoch - 908us/step\n",
      "Epoch 12/30\n",
      "210/210 - 0s - loss: 0.3837 - accuracy: 0.9019 - 207ms/epoch - 988us/step\n",
      "Epoch 13/30\n",
      "210/210 - 0s - loss: 0.3661 - accuracy: 0.9067 - 244ms/epoch - 1ms/step\n",
      "Epoch 14/30\n",
      "210/210 - 0s - loss: 0.3511 - accuracy: 0.9119 - 258ms/epoch - 1ms/step\n",
      "Epoch 15/30\n",
      "210/210 - 0s - loss: 0.3385 - accuracy: 0.9176 - 221ms/epoch - 1ms/step\n",
      "Epoch 16/30\n",
      "210/210 - 0s - loss: 0.3278 - accuracy: 0.9195 - 193ms/epoch - 919us/step\n",
      "Epoch 17/30\n",
      "210/210 - 0s - loss: 0.3189 - accuracy: 0.9205 - 184ms/epoch - 877us/step\n",
      "Epoch 18/30\n",
      "210/210 - 0s - loss: 0.3115 - accuracy: 0.9248 - 192ms/epoch - 913us/step\n",
      "Epoch 19/30\n",
      "210/210 - 0s - loss: 0.3050 - accuracy: 0.9286 - 184ms/epoch - 874us/step\n",
      "Epoch 20/30\n",
      "210/210 - 0s - loss: 0.2998 - accuracy: 0.9281 - 206ms/epoch - 982us/step\n",
      "Epoch 21/30\n",
      "210/210 - 0s - loss: 0.2954 - accuracy: 0.9300 - 210ms/epoch - 1ms/step\n",
      "Epoch 22/30\n",
      "210/210 - 0s - loss: 0.2915 - accuracy: 0.9286 - 195ms/epoch - 927us/step\n",
      "Epoch 23/30\n",
      "210/210 - 0s - loss: 0.2882 - accuracy: 0.9290 - 213ms/epoch - 1ms/step\n",
      "Epoch 24/30\n",
      "210/210 - 0s - loss: 0.2852 - accuracy: 0.9324 - 222ms/epoch - 1ms/step\n",
      "Epoch 25/30\n",
      "210/210 - 0s - loss: 0.2826 - accuracy: 0.9329 - 189ms/epoch - 902us/step\n",
      "Epoch 26/30\n",
      "210/210 - 0s - loss: 0.2802 - accuracy: 0.9310 - 194ms/epoch - 923us/step\n",
      "Epoch 27/30\n",
      "210/210 - 0s - loss: 0.2782 - accuracy: 0.9333 - 211ms/epoch - 1ms/step\n",
      "Epoch 28/30\n",
      "210/210 - 0s - loss: 0.2763 - accuracy: 0.9362 - 216ms/epoch - 1ms/step\n",
      "Epoch 29/30\n",
      "210/210 - 0s - loss: 0.2747 - accuracy: 0.9352 - 227ms/epoch - 1ms/step\n",
      "Epoch 30/30\n",
      "210/210 - 0s - loss: 0.2732 - accuracy: 0.9362 - 266ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c1782a60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Sequential model created above to the training dataset without validation set\n",
    "model.fit(x=scaled_train_samples, \n",
    "          y = train_labels, \n",
    "          batch_size=10, \n",
    "          epochs = 30, \n",
    "          shuffle = True, \n",
    "          verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0631183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 - 1s - loss: 0.2755 - accuracy: 0.9291 - val_loss: 0.2412 - val_accuracy: 0.9619 - 512ms/epoch - 3ms/step\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.2744 - accuracy: 0.9333 - val_loss: 0.2391 - val_accuracy: 0.9619 - 269ms/epoch - 1ms/step\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.2734 - accuracy: 0.9333 - val_loss: 0.2374 - val_accuracy: 0.9619 - 251ms/epoch - 1ms/step\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.2727 - accuracy: 0.9333 - val_loss: 0.2361 - val_accuracy: 0.9619 - 241ms/epoch - 1ms/step\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.2719 - accuracy: 0.9386 - val_loss: 0.2345 - val_accuracy: 0.9619 - 221ms/epoch - 1ms/step\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.2710 - accuracy: 0.9333 - val_loss: 0.2337 - val_accuracy: 0.9619 - 221ms/epoch - 1ms/step\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.2704 - accuracy: 0.9381 - val_loss: 0.2318 - val_accuracy: 0.9619 - 335ms/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.2697 - accuracy: 0.9354 - val_loss: 0.2315 - val_accuracy: 0.9619 - 239ms/epoch - 1ms/step\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.2690 - accuracy: 0.9349 - val_loss: 0.2300 - val_accuracy: 0.9619 - 206ms/epoch - 1ms/step\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.2683 - accuracy: 0.9344 - val_loss: 0.2300 - val_accuracy: 0.9667 - 222ms/epoch - 1ms/step\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.2677 - accuracy: 0.9376 - val_loss: 0.2284 - val_accuracy: 0.9619 - 242ms/epoch - 1ms/step\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.2671 - accuracy: 0.9386 - val_loss: 0.2269 - val_accuracy: 0.9619 - 284ms/epoch - 2ms/step\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.2665 - accuracy: 0.9333 - val_loss: 0.2269 - val_accuracy: 0.9667 - 246ms/epoch - 1ms/step\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.2661 - accuracy: 0.9339 - val_loss: 0.2259 - val_accuracy: 0.9619 - 208ms/epoch - 1ms/step\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.2656 - accuracy: 0.9365 - val_loss: 0.2245 - val_accuracy: 0.9619 - 220ms/epoch - 1ms/step\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.2649 - accuracy: 0.9333 - val_loss: 0.2236 - val_accuracy: 0.9619 - 245ms/epoch - 1ms/step\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.2644 - accuracy: 0.9381 - val_loss: 0.2226 - val_accuracy: 0.9619 - 224ms/epoch - 1ms/step\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.2642 - accuracy: 0.9333 - val_loss: 0.2223 - val_accuracy: 0.9619 - 219ms/epoch - 1ms/step\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.2635 - accuracy: 0.9370 - val_loss: 0.2217 - val_accuracy: 0.9619 - 215ms/epoch - 1ms/step\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.2631 - accuracy: 0.9376 - val_loss: 0.2206 - val_accuracy: 0.9619 - 237ms/epoch - 1ms/step\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2627 - accuracy: 0.9344 - val_loss: 0.2205 - val_accuracy: 0.9667 - 241ms/epoch - 1ms/step\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2624 - accuracy: 0.9370 - val_loss: 0.2200 - val_accuracy: 0.9667 - 224ms/epoch - 1ms/step\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2619 - accuracy: 0.9386 - val_loss: 0.2193 - val_accuracy: 0.9667 - 253ms/epoch - 1ms/step\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2615 - accuracy: 0.9392 - val_loss: 0.2186 - val_accuracy: 0.9619 - 252ms/epoch - 1ms/step\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2610 - accuracy: 0.9370 - val_loss: 0.2190 - val_accuracy: 0.9667 - 245ms/epoch - 1ms/step\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2610 - accuracy: 0.9376 - val_loss: 0.2183 - val_accuracy: 0.9667 - 286ms/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2605 - accuracy: 0.9402 - val_loss: 0.2169 - val_accuracy: 0.9619 - 248ms/epoch - 1ms/step\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2600 - accuracy: 0.9418 - val_loss: 0.2160 - val_accuracy: 0.9619 - 268ms/epoch - 1ms/step\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2599 - accuracy: 0.9376 - val_loss: 0.2157 - val_accuracy: 0.9619 - 227ms/epoch - 1ms/step\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2596 - accuracy: 0.9370 - val_loss: 0.2157 - val_accuracy: 0.9667 - 259ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c3314580>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Sequential model created above to the training dataset with validation set\n",
    "model.fit(x=scaled_train_samples, \n",
    "          y = train_labels, \n",
    "          validation_split = 0.1 ,\n",
    "          batch_size=10, \n",
    "          epochs = 30, \n",
    "          shuffle = True, \n",
    "          verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52eec36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create test data\n",
    "test_labels = []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf40b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # ~5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    # ~5% of older individuals who did not experience side effetcs\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    # ~95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    # ~95% of older individuals who did experience side effetcs\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fed7be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = np.array(test_samples)\n",
    "test_labels= np.array(test_labels)\n",
    "test_samples,test_labels = shuffle(test_samples,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25201d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ac3c185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - 122ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predict\n",
    "prediction = model.predict(x=scaled_test_samples, batch_size=10, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e136b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71828574 0.2817142 ]\n",
      " [0.16205397 0.837946  ]\n",
      " [0.03045446 0.96954554]\n",
      " [0.9675245  0.03247544]\n",
      " [0.04153432 0.9584657 ]\n",
      " [0.9673972  0.03260278]\n",
      " [0.9397683  0.06023164]\n",
      " [0.16205397 0.837946  ]\n",
      " [0.28778467 0.71221536]\n",
      " [0.8158705  0.18412943]\n",
      " [0.05227836 0.9477216 ]\n",
      " [0.9674736  0.03252631]\n",
      " [0.9591842  0.04081581]\n",
      " [0.1178884  0.8821116 ]\n",
      " [0.41252792 0.587472  ]\n",
      " [0.95133626 0.04866381]\n",
      " [0.96744823 0.03255178]\n",
      " [0.05227836 0.9477216 ]\n",
      " [0.9676388  0.03236124]\n",
      " [0.16205397 0.837946  ]\n",
      " [0.02408161 0.9759184 ]\n",
      " [0.41252792 0.587472  ]\n",
      " [0.5946763  0.4053236 ]\n",
      " [0.96575236 0.03424769]\n",
      " [0.10977654 0.8902235 ]\n",
      " [0.05641066 0.9435893 ]\n",
      " [0.967588   0.03241195]\n",
      " [0.9675627  0.03243733]\n",
      " [0.08831686 0.91168314]\n",
      " [0.71828574 0.2817142 ]\n",
      " [0.96744823 0.03255178]\n",
      " [0.96760076 0.03239927]\n",
      " [0.96740997 0.03259002]\n",
      " [0.03292162 0.9670784 ]\n",
      " [0.02057637 0.97942364]\n",
      " [0.0608486  0.93915135]\n",
      " [0.08831686 0.91168314]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.9676514  0.03234858]\n",
      " [0.25154638 0.7484536 ]\n",
      " [0.04485755 0.95514244]\n",
      " [0.03045446 0.96954554]\n",
      " [0.02408161 0.9759184 ]\n",
      " [0.05641066 0.9435893 ]\n",
      " [0.5946763  0.4053236 ]\n",
      " [0.41252792 0.587472  ]\n",
      " [0.63819677 0.36180323]\n",
      " [0.04843324 0.95156676]\n",
      " [0.96740997 0.03259002]\n",
      " [0.78657496 0.21342504]\n",
      " [0.08831686 0.91168314]\n",
      " [0.41252792 0.587472  ]\n",
      " [0.10977654 0.8902235 ]\n",
      " [0.0608486  0.93915135]\n",
      " [0.96740997 0.03259002]\n",
      " [0.92581034 0.07418969]\n",
      " [0.9674355  0.03256452]\n",
      " [0.9674864  0.03251359]\n",
      " [0.9673717  0.0326283 ]\n",
      " [0.9674228  0.03257726]\n",
      " [0.95133626 0.04866381]\n",
      " [0.78657496 0.21342504]\n",
      " [0.5037258  0.4962742 ]\n",
      " [0.03844736 0.9615526 ]\n",
      " [0.5037258  0.4962742 ]\n",
      " [0.966745   0.03325499]\n",
      " [0.03292162 0.9670784 ]\n",
      " [0.07071899 0.92928094]\n",
      " [0.9674864  0.03251359]\n",
      " [0.01901617 0.98098385]\n",
      " [0.01901617 0.98098385]\n",
      " [0.9484155  0.05158452]\n",
      " [0.96751183 0.03248815]\n",
      " [0.0608486  0.93915135]\n",
      " [0.16205397 0.837946  ]\n",
      " [0.12651443 0.87348557]\n",
      " [0.13567464 0.8643254 ]\n",
      " [0.04843324 0.95156676]\n",
      " [0.8158705  0.18412943]\n",
      " [0.18864937 0.81135064]\n",
      " [0.9673972  0.03260278]\n",
      " [0.9676514  0.03234858]\n",
      " [0.12651443 0.87348557]\n",
      " [0.28778467 0.71221536]\n",
      " [0.71828574 0.2817142 ]\n",
      " [0.96744823 0.03255178]\n",
      " [0.9674991  0.03250086]\n",
      " [0.5496154  0.45038456]\n",
      " [0.07071899 0.92928094]\n",
      " [0.25154638 0.7484536 ]\n",
      " [0.9397683  0.06023164]\n",
      " [0.0950122  0.9049878 ]\n",
      " [0.01901617 0.98098385]\n",
      " [0.05641066 0.9435893 ]\n",
      " [0.90251386 0.09748621]\n",
      " [0.02226167 0.9777384 ]\n",
      " [0.36871362 0.6312864 ]\n",
      " [0.9674228  0.03257726]\n",
      " [0.9673972  0.03260278]\n",
      " [0.25154638 0.7484536 ]\n",
      " [0.28778467 0.71221536]\n",
      " [0.04843324 0.95156676]\n",
      " [0.08205058 0.9179494 ]\n",
      " [0.9676388  0.03236124]\n",
      " [0.96755    0.03245003]\n",
      " [0.10977654 0.8902235 ]\n",
      " [0.13567464 0.8643254 ]\n",
      " [0.63819677 0.36180323]\n",
      " [0.04485755 0.95514244]\n",
      " [0.03292162 0.9670784 ]\n",
      " [0.9676134  0.03238659]\n",
      " [0.9674736  0.03252631]\n",
      " [0.967588   0.03241195]\n",
      " [0.9484155  0.05158452]\n",
      " [0.05227836 0.9477216 ]\n",
      " [0.96757543 0.03242464]\n",
      " [0.10977654 0.8902235 ]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.96760076 0.03239927]\n",
      " [0.9674228  0.03257726]\n",
      " [0.05227836 0.9477216 ]\n",
      " [0.03844736 0.9615526 ]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.03045446 0.96954554]\n",
      " [0.6795621  0.32043797]\n",
      " [0.05227836 0.9477216 ]\n",
      " [0.5496154  0.45038456]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.12651443 0.87348557]\n",
      " [0.21847156 0.7815284 ]\n",
      " [0.02226167 0.9777384 ]\n",
      " [0.86495215 0.13504787]\n",
      " [0.16205397 0.837946  ]\n",
      " [0.03045446 0.96954554]\n",
      " [0.03844736 0.9615526 ]\n",
      " [0.966745   0.03325499]\n",
      " [0.9484155  0.05158452]\n",
      " [0.04153432 0.9584657 ]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.08831686 0.91168314]\n",
      " [0.9676261  0.03237391]\n",
      " [0.10215823 0.89784175]\n",
      " [0.95409954 0.04590048]\n",
      " [0.28778467 0.71221536]\n",
      " [0.01901617 0.98098385]\n",
      " [0.8158705  0.18412943]\n",
      " [0.02604637 0.9739536 ]\n",
      " [0.95409954 0.04590048]\n",
      " [0.07071899 0.92928094]\n",
      " [0.04153432 0.9584657 ]\n",
      " [0.7540236  0.24597633]\n",
      " [0.9674991  0.03250086]\n",
      " [0.9615199  0.03848009]\n",
      " [0.96755    0.03245003]\n",
      " [0.41252792 0.587472  ]\n",
      " [0.95133626 0.04866381]\n",
      " [0.04485755 0.95514244]\n",
      " [0.18864937 0.81135064]\n",
      " [0.9676514  0.03234858]\n",
      " [0.13567464 0.8643254 ]\n",
      " [0.0281668  0.9718332 ]\n",
      " [0.13567464 0.8643254 ]\n",
      " [0.71828574 0.2817142 ]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.88506144 0.11493859]\n",
      " [0.0608486  0.93915135]\n",
      " [0.78657496 0.21342504]\n",
      " [0.9674864  0.03251359]\n",
      " [0.04153432 0.9584657 ]\n",
      " [0.02604637 0.9739536 ]\n",
      " [0.90251386 0.09748621]\n",
      " [0.9675627  0.03243733]\n",
      " [0.41252792 0.587472  ]\n",
      " [0.9674228  0.03257726]\n",
      " [0.04485755 0.95514244]\n",
      " [0.95671314 0.04328692]\n",
      " [0.18864937 0.81135064]\n",
      " [0.9397683  0.06023164]\n",
      " [0.18864937 0.81135064]\n",
      " [0.05641066 0.9435893 ]\n",
      " [0.63819677 0.36180323]\n",
      " [0.967588   0.03241195]\n",
      " [0.7540236  0.24597633]\n",
      " [0.25154638 0.7484536 ]\n",
      " [0.32696304 0.673037  ]\n",
      " [0.9676514  0.03234858]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.9674991  0.03250086]\n",
      " [0.04153432 0.9584657 ]\n",
      " [0.02408161 0.9759184 ]\n",
      " [0.36871362 0.6312864 ]\n",
      " [0.9676134  0.03238659]\n",
      " [0.02226167 0.9777384 ]\n",
      " [0.10215823 0.89784175]\n",
      " [0.96746093 0.03253904]\n",
      " [0.02604637 0.9739536 ]\n",
      " [0.05641066 0.9435893 ]\n",
      " [0.9674991  0.03250086]\n",
      " [0.9676134  0.03238659]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.04153432 0.9584657 ]\n",
      " [0.28778467 0.71221536]\n",
      " [0.90251386 0.09748621]\n",
      " [0.1178884  0.8821116 ]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.9674736  0.03252631]\n",
      " [0.93345207 0.06654795]\n",
      " [0.45777306 0.54222697]\n",
      " [0.18864937 0.81135064]\n",
      " [0.10977654 0.8902235 ]\n",
      " [0.0950122  0.9049878 ]\n",
      " [0.9674355  0.03256452]\n",
      " [0.07619172 0.9238083 ]\n",
      " [0.96766406 0.03233592]\n",
      " [0.1178884  0.8821116 ]\n",
      " [0.9615199  0.03848009]\n",
      " [0.95671314 0.04328692]\n",
      " [0.02604637 0.9739536 ]\n",
      " [0.05641066 0.9435893 ]\n",
      " [0.96744823 0.03255178]\n",
      " [0.12651443 0.87348557]\n",
      " [0.9674864  0.03251359]\n",
      " [0.08205058 0.9179494 ]\n",
      " [0.9615199  0.03848009]\n",
      " [0.9674991  0.03250086]\n",
      " [0.96575236 0.03424769]\n",
      " [0.7540236  0.24597633]\n",
      " [0.92581034 0.07418969]\n",
      " [0.13567464 0.8643254 ]\n",
      " [0.95671314 0.04328692]\n",
      " [0.5946763  0.4053236 ]\n",
      " [0.0608486  0.93915135]\n",
      " [0.96755    0.03245003]\n",
      " [0.08831686 0.91168314]\n",
      " [0.86495215 0.13504787]\n",
      " [0.9397683  0.06023164]\n",
      " [0.8158705  0.18412943]\n",
      " [0.96757543 0.03242464]\n",
      " [0.9674355  0.03256452]\n",
      " [0.96760076 0.03239927]\n",
      " [0.02408161 0.9759184 ]\n",
      " [0.9674736  0.03252631]\n",
      " [0.9484155  0.05158452]\n",
      " [0.966745   0.03325499]\n",
      " [0.9674991  0.03250086]\n",
      " [0.96755    0.03245003]\n",
      " [0.12651443 0.87348557]\n",
      " [0.9397683  0.06023164]\n",
      " [0.25154638 0.7484536 ]\n",
      " [0.9674355  0.03256452]\n",
      " [0.36871362 0.6312864 ]\n",
      " [0.28778467 0.71221536]\n",
      " [0.7540236  0.24597633]\n",
      " [0.96751183 0.03248815]\n",
      " [0.96760076 0.03239927]\n",
      " [0.9675627  0.03243733]\n",
      " [0.0950122  0.9049878 ]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.18864937 0.81135064]\n",
      " [0.93345207 0.06654795]\n",
      " [0.9676134  0.03238659]\n",
      " [0.04843324 0.95156676]\n",
      " [0.9676261  0.03237391]\n",
      " [0.05227836 0.9477216 ]\n",
      " [0.90251386 0.09748621]\n",
      " [0.08831686 0.91168314]\n",
      " [0.9673972  0.03260278]\n",
      " [0.03844736 0.9615526 ]\n",
      " [0.07619172 0.9238083 ]\n",
      " [0.9676514  0.03234858]\n",
      " [0.0950122  0.9049878 ]\n",
      " [0.92581034 0.07418969]\n",
      " [0.0281668  0.9718332 ]\n",
      " [0.0608486  0.93915135]\n",
      " [0.96760076 0.03239927]\n",
      " [0.9673972  0.03260278]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.93345207 0.06654795]\n",
      " [0.9397683  0.06023164]\n",
      " [0.02226167 0.9777384 ]\n",
      " [0.5496154  0.45038456]\n",
      " [0.02057637 0.97942364]\n",
      " [0.9591842  0.04081581]\n",
      " [0.0950122  0.9049878 ]\n",
      " [0.25154638 0.7484536 ]\n",
      " [0.04153432 0.9584657 ]\n",
      " [0.86495215 0.13504787]\n",
      " [0.03292162 0.9670784 ]\n",
      " [0.41252792 0.587472  ]\n",
      " [0.96744823 0.03255178]\n",
      " [0.7540236  0.24597633]\n",
      " [0.1178884  0.8821116 ]\n",
      " [0.9160518  0.08394814]\n",
      " [0.03844736 0.9615526 ]\n",
      " [0.9674355  0.03256452]\n",
      " [0.96760076 0.03239927]\n",
      " [0.02226167 0.9777384 ]\n",
      " [0.96372706 0.03627298]\n",
      " [0.04485755 0.95514244]\n",
      " [0.84195286 0.15804714]\n",
      " [0.02226167 0.9777384 ]\n",
      " [0.9591842  0.04081581]\n",
      " [0.02057637 0.97942364]\n",
      " [0.9676261  0.03237391]\n",
      " [0.9674736  0.03252631]\n",
      " [0.36871362 0.6312864 ]\n",
      " [0.9673845  0.03261554]\n",
      " [0.92581034 0.07418969]\n",
      " [0.03045446 0.96954554]\n",
      " [0.9484155  0.05158452]\n",
      " [0.02408161 0.9759184 ]\n",
      " [0.12651443 0.87348557]\n",
      " [0.95409954 0.04590048]\n",
      " [0.01901617 0.98098385]\n",
      " [0.02604637 0.9739536 ]\n",
      " [0.96575236 0.03424769]\n",
      " [0.01901617 0.98098385]\n",
      " [0.9675245  0.03247544]\n",
      " [0.84195286 0.15804714]\n",
      " [0.9484155  0.05158452]\n",
      " [0.90251386 0.09748621]\n",
      " [0.10215823 0.89784175]\n",
      " [0.21847156 0.7815284 ]\n",
      " [0.95671314 0.04328692]\n",
      " [0.9484155  0.05158452]\n",
      " [0.03045446 0.96954554]\n",
      " [0.05641066 0.9435893 ]\n",
      " [0.04843324 0.95156676]\n",
      " [0.9615199  0.03848009]\n",
      " [0.96575236 0.03424769]\n",
      " [0.02408161 0.9759184 ]\n",
      " [0.07619172 0.9238083 ]\n",
      " [0.9675373  0.03246273]\n",
      " [0.02057637 0.97942364]\n",
      " [0.96760076 0.03239927]\n",
      " [0.966745   0.03325499]\n",
      " [0.9676514  0.03234858]\n",
      " [0.9675373  0.03246273]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.21847156 0.7815284 ]\n",
      " [0.9676261  0.03237391]\n",
      " [0.84195286 0.15804714]\n",
      " [0.9674355  0.03256452]\n",
      " [0.03292162 0.9670784 ]\n",
      " [0.02604637 0.9739536 ]\n",
      " [0.90251386 0.09748621]\n",
      " [0.18864937 0.81135064]\n",
      " [0.03045446 0.96954554]\n",
      " [0.86495215 0.13504787]\n",
      " [0.7540236  0.24597633]\n",
      " [0.9674736  0.03252631]\n",
      " [0.96744823 0.03255178]\n",
      " [0.07071899 0.92928094]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.05641066 0.9435893 ]\n",
      " [0.02226167 0.9777384 ]\n",
      " [0.16205397 0.837946  ]\n",
      " [0.13567464 0.8643254 ]\n",
      " [0.06561143 0.9343886 ]\n",
      " [0.9675627  0.03243733]\n",
      " [0.9674736  0.03252631]\n",
      " [0.96766406 0.03233592]\n",
      " [0.9676261  0.03237391]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.966745   0.03325499]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.86495215 0.13504787]\n",
      " [0.9674228  0.03257726]\n",
      " [0.9484155  0.05158452]\n",
      " [0.02057637 0.97942364]\n",
      " [0.9676134  0.03238659]\n",
      " [0.5946763  0.4053236 ]\n",
      " [0.0281668  0.9718332 ]\n",
      " [0.5946763  0.4053236 ]\n",
      " [0.6795621  0.32043797]\n",
      " [0.02604637 0.9739536 ]\n",
      " [0.45777306 0.54222697]\n",
      " [0.25154638 0.7484536 ]\n",
      " [0.96757543 0.03242464]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.9160518  0.08394814]\n",
      " [0.9676134  0.03238659]\n",
      " [0.78657496 0.21342504]\n",
      " [0.90251386 0.09748621]\n",
      " [0.08205058 0.9179494 ]\n",
      " [0.1178884  0.8821116 ]\n",
      " [0.96760076 0.03239927]\n",
      " [0.28778467 0.71221536]\n",
      " [0.78657496 0.21342504]\n",
      " [0.93345207 0.06654795]\n",
      " [0.1178884  0.8821116 ]\n",
      " [0.03292162 0.9670784 ]\n",
      " [0.32696304 0.673037  ]\n",
      " [0.03292162 0.9670784 ]\n",
      " [0.10977654 0.8902235 ]\n",
      " [0.45777306 0.54222697]\n",
      " [0.9397683  0.06023164]\n",
      " [0.9673845  0.03261554]\n",
      " [0.9676261  0.03237391]\n",
      " [0.07619172 0.9238083 ]\n",
      " [0.04153432 0.9584657 ]\n",
      " [0.21847156 0.7815284 ]\n",
      " [0.14584066 0.8541593 ]\n",
      " [0.12651443 0.87348557]\n",
      " [0.966745   0.03325499]\n",
      " [0.95671314 0.04328692]\n",
      " [0.96372706 0.03627298]\n",
      " [0.96757543 0.03242464]\n",
      " [0.0608486  0.93915135]\n",
      " [0.36871362 0.6312864 ]\n",
      " [0.02604637 0.9739536 ]\n",
      " [0.16205397 0.837946  ]\n",
      " [0.9675373  0.03246273]\n",
      " [0.9674355  0.03256452]\n",
      " [0.9397683  0.06023164]\n",
      " [0.96372706 0.03627298]\n",
      " [0.95409954 0.04590048]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9268d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_prediction = np.argmax(prediction, axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6a96d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1\n",
      " 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0\n",
      " 0 0 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0\n",
      " 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 1\n",
      " 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1\n",
      " 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
      " 0 0 0 0 1 1 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(rounded_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96465fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f1d5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81042047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm, classes,\n",
    "           normalize = False,\n",
    "           title=\"Confusion Matrix\",\n",
    "           cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm,interpration='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks=np.arange(len(classes))\n",
    "    plt.xticks(tick_marks,classes,rotation=45)\n",
    "    plt.yticks(tick_marks,classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
